const { TextToSpeechClient } = require('@google-cloud/text-to-speech');
const path = require('path');

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { text } = req.body;

  if (!text || text.trim() === '') {
    return res.status(400).json({ error: 'Text is required' });
  }

  try {
    const trimmedText = text.trim();
    console.log('ğŸ­ Google Cloud TTS (Vaya) ì‹œì‘:', {
      text: trimmedText.slice(0, 50) + '...',
      length: trimmedText.length,
      timestamp: new Date().toISOString()
    });

    // ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ
    const keyFilePath = path.join(process.cwd(), 'pages', 'api', 'vaya-voice-9a75a34cc232.json');
    
    // Google Cloud Text-to-Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    const client = new TextToSpeechClient({
      keyFilename: keyFilePath,
      projectId: 'vaya-voice'
    });

    // í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€ í•¨ìˆ˜
    const detectLanguage = (text) => {
      const koreanRegex = /[ã„±-ã…|ã…-ã…£|ê°€-í£]/;
      return koreanRegex.test(text) ? 'ko-KR' : 'en-US';
    };

    const detectedLanguage = detectLanguage(text.trim());
    console.log('ğŸŒ ê°ì§€ëœ ì–¸ì–´:', detectedLanguage);

    // Vaya ìŒì„± ì„¤ì • (ë” ë‚®ê³  ì„±ìˆ™í•œ ìŒì„±)
    const voiceConfig = detectedLanguage === 'ko-KR' ? {
      languageCode: 'ko-KR',
      name: 'ko-KR-Neural2-C', // í•œêµ­ì–´ ë‚¨ì„± ìŒì„± (ê°€ì¥ ë‚®ì€ í†¤)
      ssmlGender: 'MALE'
    } : {
      languageCode: 'en-US', 
      name: 'en-US-Neural2-A', // ì˜ì–´ ë‚¨ì„± ìŒì„± (ë” ê¹Šê³  ì„±ìˆ™í•œ ëª©ì†Œë¦¬)
      ssmlGender: 'MALE'
    };

    // SSMLë¡œ ë” ë‚®ê³  ì„¬ì„¸í•œ ëª©ì†Œë¦¬ ë§Œë“¤ê¸°
    const ssmlText = `<speak>
      <prosody pitch="-4st">
        ${text.trim()}
      </prosody>
    </speak>`;

    const request = {
      input: { ssml: ssmlText },
      voice: voiceConfig,
      audioConfig: {
        audioEncoding: 'MP3',
        effectsProfileId: ['headphone-class-device'], // í—¤ë“œí° ìµœì í™”
        // ë” ë‚®ê³  ì„±ìˆ™í•œ ìŒì„±ì„ ìœ„í•œ ì„¤ì •
        pitch: -5.0, // ìŒì„±ì„ ë” ë‚®ê²Œ
        speakingRate: 0.85, // ì¡°ê¸ˆ ë” ì²œì²œíˆ ë§í•˜ê¸°
        enableTimePointing: true
      }
    };

    console.log('ğŸ­ Vaya ìŒì„± ìš”ì²­ (SSML + ì—ì½”):', {
      voice: request.voice.name,
      language: request.voice.languageCode,
      pitch: request.audioConfig.pitch,
      speakingRate: request.audioConfig.speakingRate,
      ssml: 'prosody pitch="-4st" (ê¸°ë³¸ ì†ë„)'
    });

    // Google Cloud TTS API í˜¸ì¶œ
    const [response] = await client.synthesizeSpeech(request);

    if (!response.audioContent) {
      throw new Error('No audio content received from Google TTS');
    }

    // Base64ë¡œ ì¸ì½”ë”©
    const audioBase64 = response.audioContent.toString('base64');
    
    const voiceName = detectedLanguage === 'ko-KR' ? 
      'Vaya (ko-KR-Neural2-C, SSML + ì—ì½”)' : 
      'Vaya (en-US-Neural2-A, SSML + ì—ì½”)';
    
    console.log('âœ… Google Cloud TTS (Vaya) + SSML + ì—ì½” íš¨ê³¼ ì„±ê³µ!');
    
    res.status(200).json({ 
      audioContent: audioBase64,
      contentType: 'audio/mpeg',
      source: 'google-cloud-tts',
      voice: voiceName,
      language: detectedLanguage
    });

  } catch (error) {
    console.error('ğŸ”¥ Google Cloud TTS (Vaya) ì˜¤ë¥˜:', error.message);
    
    // Google TTS ì‹¤íŒ¨ ì‹œ ë¸Œë¼ìš°ì € TTS fallback
    return res.status(500).json({ 
      error: 'Google Cloud TTS failed', 
      fallback: true,
      details: error.message 
    });
  }
} 