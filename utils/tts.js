// TTS ê´€ë ¨ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
let currentAudio = null;
let currentUtterance = null;
let isSpeaking = false;
let currentAudioContext = null;
let currentAudioSource = null;
let lastProcessedText = null; // ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€

/**
 * Google Cloud TTSë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì‹¤íŒ¨ ì‹œ ë¸Œë¼ìš°ì € TTSë¥¼ ì‚¬ìš©
 * @param {string} text - ì½ì„ í…ìŠ¤íŠ¸
 * @returns {Promise<boolean>} - ì„±ê³µ ì—¬ë¶€
 */
export const speakText = async (text) => {
  if (!text || text.trim() === '') {
    console.warn('âš ï¸ ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì½ì„ ìˆ˜ ì—†ìŒ');
    return;
  }

  const trimmedText = text.trim();
  
  // ğŸ¯ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€: ê°™ì€ í…ìŠ¤íŠ¸ëŠ” ë¬´ì‹œ
  if (lastProcessedText === trimmedText) {
    console.log('âš ï¸ ë™ì¼í•œ í…ìŠ¤íŠ¸ ì¤‘ë³µ ìš”ì²­ ë¬´ì‹œ:', trimmedText.slice(0, 30) + '...');
    return;
  }

  console.log('ğŸ­ TTS ì‹œì‘:', trimmedText.slice(0, 50) + '...');
  lastProcessedText = trimmedText; // í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í…ìŠ¤íŠ¸ ì €ì¥

  try {
    // ê¸°ì¡´ ìŒì„± ê°•ì œ ì¤‘ì§€ (ì¤‘ìš”!)
    console.log('ğŸ”‡ ìƒˆ TTS ì‹œì‘ ì „ ëª¨ë“  ìŒì„± ì¤‘ì§€');
    stopSpeaking();
    
    // ì¤‘ì§€ ì™„ë£Œë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ëŒ€ê¸° (Web Audio API ì™„ì „ ì¤‘ì§€)
    await new Promise(resolve => setTimeout(resolve, 200));

    // 1. Google Cloud TTS (Charon) ì‹œë„
    const response = await fetch('/api/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ text: text.trim() }),
    });

    if (response.ok) {
      const data = await response.json();
      
      if (data.audioContent && data.source === 'google-cloud-tts') {
        console.log('âœ… Google Cloud TTS ì‘ë‹µ ë°›ìŒ:', data.voice);
        await playBase64Audio(data.audioContent);
        return;
      }
    }
    
    console.log('ğŸ”„ Google Cloud TTS ì‹¤íŒ¨, Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTSë¡œ ì „í™˜');
    
  } catch (error) {
    console.error('ğŸ”¥ Google Cloud TTS API í˜¸ì¶œ ì˜¤ë¥˜:', error);
    console.log('ğŸ”„ Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTSë¡œ ì „í™˜');
  }

  // 2. Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTS fallback
  try {
    await speakWithBrowserTTS(text);
  } catch (error) {
    console.error('ğŸ”¥ Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTSë„ ì‹¤íŒ¨:', error);
    throw error;
  }
};

/**
 * Google Cloud TTS ì˜¤ë””ì˜¤ ì¬ìƒ
 * @param {string} audioBase64 - Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„°
 * @returns {Promise<boolean>} - ì„±ê³µ ì—¬ë¶€
 */
const playGoogleTTS = async (audioBase64) => {
  try {
    // Base64 ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
    const audioBytes = atob(audioBase64);
    const audioArray = new Uint8Array(audioBytes.length);
    
    for (let i = 0; i < audioBytes.length; i++) {
      audioArray[i] = audioBytes.charCodeAt(i);
    }

    const audioBlob = new Blob([audioArray], { type: 'audio/mpeg' });
    const audioUrl = URL.createObjectURL(audioBlob);

    // ì˜¤ë””ì˜¤ ì¬ìƒ
    currentAudio = new Audio(audioUrl);
    
    return new Promise((resolve) => {
      currentAudio.onended = () => {
        isSpeaking = false;
        URL.revokeObjectURL(audioUrl);
        console.log('âœ… Google Cloud TTS ì¬ìƒ ì™„ë£Œ');
        resolve(true);
      };

      currentAudio.onerror = () => {
        isSpeaking = false;
        URL.revokeObjectURL(audioUrl);
        console.log('âŒ Google Cloud TTS ì¬ìƒ ì˜¤ë¥˜');
        resolve(false);
      };

      currentAudio.play().catch(() => {
        isSpeaking = false;
        URL.revokeObjectURL(audioUrl);
        console.log('âŒ Google Cloud TTS ì¬ìƒ ì‹¤íŒ¨');
        resolve(false);
      });
    });

  } catch (error) {
    console.error('Google TTS ì¬ìƒ ì˜¤ë¥˜:', error);
    isSpeaking = false;
    return false;
  }
};

/**
 * ë¸Œë¼ìš°ì € ë‚´ì¥ TTSë¥¼ ì‚¬ìš©í•˜ëŠ” fallback í•¨ìˆ˜
 * @param {string} text - ì½ì„ í…ìŠ¤íŠ¸
 * @returns {Promise<boolean>} - ì„±ê³µ ì—¬ë¶€
 */
const playBrowserTTS = async (text) => {
  return new Promise((resolve) => {
    try {
      const utterance = new SpeechSynthesisUtterance(text.trim());
      
      // ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
      const voices = speechSynthesis.getVoices();
      
      // í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€
      const detectLanguage = (text) => {
        const koreanRegex = /[ã„±-ã…|ã…-ã…£|ê°€-í£]/;
        return koreanRegex.test(text) ? 'ko-KR' : 'en-US';
      };

      const detectedLanguage = detectLanguage(text);
      console.log('ğŸŒ playBrowserTTS ì–¸ì–´ ê°ì§€:', detectedLanguage);

      let selectedVoice = null;
      
      if (detectedLanguage === 'ko-KR') {
        // í•œêµ­ì–´ ìŒì„± ìš°ì„ ìˆœìœ„
        const koreanVoices = [
          'Microsoft Heami',
          'Microsoft SunHi', 
          'Google í•œêµ­ì˜',
          'Yuna',
          'Sora'
        ];
        
        for (const koreanName of koreanVoices) {
          selectedVoice = voices.find(voice => 
            voice.name.includes(koreanName) && voice.lang.includes('ko')
          );
          if (selectedVoice) break;
        }
        
        // ëŒ€ì•ˆ: í•œêµ­ì–´ ìŒì„± ì•„ë¬´ê±°ë‚˜
        if (!selectedVoice) {
          selectedVoice = voices.find(voice => 
            voice.lang.includes('ko') || voice.lang.includes('KR')
          );
        }
      } else {
        // ì˜ì–´ Charon ìŠ¤íƒ€ì¼ ìŒì„± ìš°ì„ ìˆœìœ„
        const englishVoices = [
          'Microsoft David',
          'Microsoft Mark', 
          'Alex',
          'Daniel',
          'Fred'
        ];
        
        for (const englishName of englishVoices) {
          selectedVoice = voices.find(voice => 
            voice.name.includes(englishName) && voice.lang.includes('en')
          );
          if (selectedVoice) break;
        }
        
        // ëŒ€ì•ˆ: ì˜ì–´ ë‚¨ì„± ìŒì„±
        if (!selectedVoice) {
          selectedVoice = voices.find(voice => 
            voice.lang.includes('en') &&
            (voice.name.toLowerCase().includes('male') || 
             voice.name.toLowerCase().includes('man') ||
             voice.name.toLowerCase().includes('david') ||
             voice.name.toLowerCase().includes('alex'))
          );
        }
        
        // ìµœì¢… ëŒ€ì•ˆ: ì˜ì–´ ìŒì„± ì•„ë¬´ê±°ë‚˜
        if (!selectedVoice) {
          selectedVoice = voices.find(voice => 
            voice.lang.startsWith('en-')
          );
        }
      }
      
      // ìŒì„± ì„¤ì •
      if (selectedVoice) {
        utterance.voice = selectedVoice;
        console.log('ğŸ­ Charon ìŠ¤íƒ€ì¼ ìŒì„± ì„ íƒ:', selectedVoice.name, selectedVoice.lang);
      } else {
        console.log('ğŸ”Š ë¸Œë¼ìš°ì € TTS - ê¸°ë³¸ ìŒì„± ì‚¬ìš©');
      }
      
      // ê¸°ë³¸ ìŒì„± ì„¤ì • ì‚¬ìš©
      utterance.lang = selectedVoice ? selectedVoice.lang : 'en-US';
      
      // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
      utterance.onstart = () => {
        isSpeaking = true;
        console.log('ğŸ­ Charon ìŒì„± ì‹œì‘');
      };

      utterance.onend = () => {
        isSpeaking = false;
        currentUtterance = null;
        console.log('ğŸ­ Charon ìŒì„± ì™„ë£Œ');
        resolve(true);
      };

      utterance.onerror = (event) => {
        isSpeaking = false;
        currentUtterance = null;
        console.error('ğŸ­ Charon ìŒì„± ì˜¤ë¥˜:', event.error);
        resolve(false);
      };

      // í˜„ì¬ utterance ì €ì¥
      currentUtterance = utterance;
      
      // ìŒì„± ì¬ìƒ
      speechSynthesis.speak(utterance);
      
    } catch (error) {
      console.error('ë¸Œë¼ìš°ì € TTS ì˜¤ë¥˜:', error);
      isSpeaking = false;
      resolve(false);
    }
  });
};

/**
 * í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ìŒì„± ì¤‘ì§€
 */
export const stopSpeaking = () => {
  return new Promise(async (resolve) => {
    console.log('ğŸ”‡ ëª¨ë“  ìŒì„± ì¤‘ì§€ ì‹œë„');
    
    // 1. Web Audio API ì¤‘ì§€
    if (currentAudioContext) {
      console.log('- Web Audio Context ì¤‘ì§€');
      await currentAudioContext.close().catch(console.error);
      currentAudioContext = null;
    }
    
    if (currentAudioSource) {
      console.log('- Audio Source ì¤‘ì§€');
      try {
        currentAudioSource.stop();
      } catch (e) {
        console.log('- Audio Source ì´ë¯¸ ì¤‘ì§€ë¨');
      }
      currentAudioSource = null;
    }

    // 2. HTML5 Audio ì¤‘ì§€
    if (currentAudio) {
      console.log('- HTML5 Audio ì¤‘ì§€');
      currentAudio.pause();
      currentAudio.currentTime = 0;
      currentAudio.src = ''; // ë¦¬ì†ŒìŠ¤ í•´ì œ
      currentAudio = null;
    }

    // 3. ë¸Œë¼ìš°ì € TTS ì¤‘ì§€
    if (window.speechSynthesis) {
      console.log('- ë¸Œë¼ìš°ì € TTS ì¤‘ì§€');
      window.speechSynthesis.cancel();
      // ì™„ì „í•œ ì¤‘ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ëŒ€ê¸°
      await new Promise(r => setTimeout(r, 50));
    }

    if (currentUtterance) {
      console.log('- í˜„ì¬ Utterance ì¤‘ì§€');
      currentUtterance = null;
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    isSpeaking = false;
    lastProcessedText = null;
    
    // ëª¨ë“  ì¤‘ì§€ ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ì§§ê²Œ ëŒ€ê¸°
    await new Promise(r => setTimeout(r, 50));
    
    console.log('âœ… ëª¨ë“  ìŒì„± ì¤‘ì§€ ì™„ë£Œ');
    resolve();
  });
};

/**
 * TTS ì¬ìƒ ìƒíƒœ í™•ì¸
 * @returns {boolean} - ì¬ìƒ ì¤‘ ì—¬ë¶€
 */
export const getIsSpeaking = () => {
  return isSpeaking;
};

// Base64 ì˜¤ë””ì˜¤ ì¬ìƒ í•¨ìˆ˜ (ì—ì½” íš¨ê³¼ ì ìš©)
const playBase64Audio = (audioBase64) => {
  return new Promise(async (resolve, reject) => {
    try {
      // Base64ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
      const byteCharacters = atob(audioBase64);
      const byteNumbers = new Array(byteCharacters.length);
      for (let i = 0; i < byteCharacters.length; i++) {
        byteNumbers[i] = byteCharacters.charCodeAt(i);
      }
      const byteArray = new Uint8Array(byteNumbers);
      const audioBlob = new Blob([byteArray], { type: 'audio/mpeg' });
      
      // Web Audio APIë¥¼ ì‚¬ìš©í•œ ì—ì½” íš¨ê³¼
      try {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const response = await fetch(URL.createObjectURL(audioBlob));
        const arrayBuffer = await response.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        
        // ì „ì—­ ë³€ìˆ˜ì— ì €ì¥ (ì¤‘ì§€ë¥¼ ìœ„í•´)
        currentAudioContext = audioContext;
        currentAudioSource = source;

        // ğŸ­ ì—ì½” íš¨ê³¼ìš© Delay Node (ì•„ì£¼ ì‚´ì§ë§Œ)
        const delay = audioContext.createDelay();
        delay.delayTime.value = 0.15; // 0.15ì´ˆ (ì‚´ì§ ì§§ì€ ë©”ì•„ë¦¬)

        // ğŸ­ ì—ì½” ê°•ë„ ì¡°ì ˆìš© Gain Node (ì•„ì£¼ ì•½í•˜ê²Œ)
        const feedback = audioContext.createGain();
        feedback.gain.value = 0.1; // ë” ì•½í•œ ë©”ì•„ë¦¬

        // ğŸ­ ì—ì½” ë³¼ë¥¨ ì¡°ì ˆ (ê¸°ë³¸ ëª©ì†Œë¦¬ë³´ë‹¤ í›¨ì”¬ ì‘ê²Œ)
        const echoGain = audioContext.createGain();
        echoGain.gain.value = 0.3; // ì—ì½”ëŠ” ì›ë³¸ì˜ 30% ë³¼ë¥¨

        // ğŸ­ ì›ë³¸ ìŒì„± ë³¼ë¥¨ ì¡°ì ˆ
        const mainGain = audioContext.createGain();
        mainGain.gain.value = 0.9; // ì›ë³¸ ìŒì„±

        // ğŸ­ ì—ì½” ë£¨í”„ ì—°ê²°
        delay.connect(feedback);
        feedback.connect(delay);

        // ğŸ­ ì˜¤ë””ì˜¤ ê²½ë¡œ ì—°ê²° (ë”œë ˆì´ ì—†ëŠ” ì›ë³¸ + ë‚®ì€ ë³¼ë¥¨ ì—ì½”)
        source.connect(mainGain); // ì›ë³¸: ë”œë ˆì´ ì—†ì´ ë°”ë¡œ ì¬ìƒ
        source.connect(delay); // ì—ì½”: ë”œë ˆì´ í›„ ì¬ìƒ
        
        mainGain.connect(audioContext.destination); // ì›ë³¸ ìŒì„± (ë”œë ˆì´ ì—†ìŒ)
        delay.connect(echoGain); // ì—ì½”ì— ë³¼ë¥¨ ì¡°ì ˆ ì ìš©
        echoGain.connect(audioContext.destination); // ì—ì½” ìŒì„± (ë‚®ì€ ë³¼ë¥¨)

        // ìƒíƒœ ì„¤ì •
        currentAudio = { 
          pause: () => source.stop(),
          currentTime: 0,
          src: URL.createObjectURL(audioBlob)
        };
        isSpeaking = true;

        console.log('ğŸ­ Google Cloud TTS (Vaya) + ìµœì í™”ëœ ì—ì½” íš¨ê³¼ ì¬ìƒ ì‹œì‘ (ì—ì½” 30% ë³¼ë¥¨)');

        source.onended = () => {
          console.log('âœ… Google Cloud TTS (Vaya) + ìµœì í™”ëœ ì—ì½” íš¨ê³¼ ì¬ìƒ ì™„ë£Œ');
          URL.revokeObjectURL(audioBlob);
          currentAudio = null;
          currentAudioContext = null;
          currentAudioSource = null;
          isSpeaking = false;
          resolve();
        };

        source.start();

      } catch (webAudioError) {
        console.warn('âš ï¸ Web Audio API ì‹¤íŒ¨, ì¼ë°˜ ì˜¤ë””ì˜¤ë¡œ ì¬ìƒ:', webAudioError);
        
        // Web Audio API ì‹¤íŒ¨ ì‹œ ì¼ë°˜ Audio ê°ì²´ ì‚¬ìš©
        const audio = new Audio(URL.createObjectURL(audioBlob));
        
        // í˜„ì¬ ì˜¤ë””ì˜¤ë¡œ ì„¤ì •
        currentAudio = audio;
        isSpeaking = true;
        
        audio.onloadeddata = () => {
          console.log('ğŸ­ Google Cloud TTS ì˜¤ë””ì˜¤ ë¡œë“œ ì™„ë£Œ');
        };
        
        audio.onplay = () => {
          console.log('ğŸ­ Google Cloud TTS (Vaya) ì¬ìƒ ì‹œì‘');
        };
        
        audio.onended = () => {
          console.log('âœ… Google Cloud TTS (Vaya) ì¬ìƒ ì™„ë£Œ');
          URL.revokeObjectURL(audio.src);
          currentAudio = null;
          isSpeaking = false;
          resolve();
        };
        
        audio.onerror = (error) => {
          console.error('ğŸ”¥ Google Cloud TTS ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
          URL.revokeObjectURL(audio.src);
          currentAudio = null;
          isSpeaking = false;
          reject(error);
        };
        
        audio.play().catch((error) => {
          currentAudio = null;
          isSpeaking = false;
          reject(error);
        });
      }
      
    } catch (error) {
      console.error('ğŸ”¥ Base64 ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜:', error);
      reject(error);
    }
  });
};

// Charon ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTS
const speakWithBrowserTTS = (text) => {
  return new Promise((resolve, reject) => {
    if (!window.speechSynthesis) {
      console.error('ğŸ”¥ ë¸Œë¼ìš°ì €ê°€ TTSë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ');
      reject(new Error('Speech synthesis not supported'));
      return;
    }

    // ê¸°ì¡´ ìŒì„± ì¤‘ì§€
    stopSpeaking();
    
    const utterance = new SpeechSynthesisUtterance(text);
    currentUtterance = utterance;
    
    // Charon ìŠ¤íƒ€ì¼ ìŒì„± ì„¤ì • ì°¾ê¸°
    const voices = window.speechSynthesis.getVoices();
    console.log('ğŸ­ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„±ë“¤:', voices.map(v => `${v.name} (${v.lang})`));
    
    // í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€
    const detectLanguage = (text) => {
      const koreanRegex = /[ã„±-ã…|ã…-ã…£|ê°€-í£]/;
      return koreanRegex.test(text) ? 'ko-KR' : 'en-US';
    };

    const detectedLanguage = detectLanguage(text);
    console.log('ğŸŒ ë¸Œë¼ìš°ì € TTS ì–¸ì–´ ê°ì§€:', detectedLanguage);

    let selectedVoice = null;
    
    if (detectedLanguage === 'ko-KR') {
      // í•œêµ­ì–´ ìŒì„± ìš°ì„ ìˆœìœ„
      const koreanPreferences = [
        'Microsoft Heami',
        'Microsoft SunHi', 
        'Google í•œêµ­ì˜',
        'Yuna',
        'Sora'
      ];
      
      for (const preference of koreanPreferences) {
        selectedVoice = voices.find(voice => 
          voice.name.includes(preference) && voice.lang.includes('ko')
        );
        if (selectedVoice) break;
      }
      
      // ëŒ€ì•ˆ: í•œêµ­ì–´ ìŒì„± ì•„ë¬´ê±°ë‚˜
      if (!selectedVoice) {
        selectedVoice = voices.find(voice => 
          voice.lang.includes('ko') || voice.lang.includes('KR')
        );
      }
    } else {
      // ì˜ì–´ Charon ìŠ¤íƒ€ì¼ ìŒì„± ìš°ì„ ìˆœìœ„
      const charonPreferences = [
        'Microsoft David',
        'Alex',
        'Daniel', 
        'Fred'
      ];
      
      for (const preference of charonPreferences) {
        selectedVoice = voices.find(voice => 
          voice.name.includes(preference) && voice.lang.includes('en')
        );
        if (selectedVoice) break;
      }
      
      // ëŒ€ì•ˆ: ì˜ì–´ ë‚¨ì„± ìŒì„±
      if (!selectedVoice) {
        selectedVoice = voices.find(voice => 
          voice.lang.includes('en') && 
          (voice.name.toLowerCase().includes('male') || 
           voice.name.toLowerCase().includes('man') ||
           voice.name.includes('David') || 
           voice.name.includes('Alex'))
        );
      }
    }
    
    // ìµœì¢… ëŒ€ì•ˆ: ê¸°ë³¸ ìŒì„±
    if (!selectedVoice && voices.length > 0) {
      selectedVoice = voices[0];
    }
    
    if (selectedVoice) {
      utterance.voice = selectedVoice;
      console.log('ğŸ­ Charon ìŠ¤íƒ€ì¼ ìŒì„± ì„ íƒ:', selectedVoice.name);
    }
    
    console.log('ğŸ­ Charon ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTS ì„¤ì •:', {
      voice: selectedVoice?.name || 'ê¸°ë³¸ ìŒì„±'
    });
    
    utterance.onstart = () => {
      console.log('ğŸ­ Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTS ì‹œì‘');
      isSpeaking = true;
    };
    
    utterance.onend = () => {
      console.log('âœ… Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTS ì™„ë£Œ');
      currentUtterance = null;
      isSpeaking = false;
      resolve();
    };
    
    utterance.onerror = (error) => {
      console.error('ğŸ”¥ Vaya ìŠ¤íƒ€ì¼ ë¸Œë¼ìš°ì € TTS ì˜¤ë¥˜:', error);
      currentUtterance = null;
      isSpeaking = false;
      reject(error);
    };
    
    // ìŒì„± ëª©ë¡ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì‹œ ëŒ€ê¸°
    setTimeout(() => {
      window.speechSynthesis.speak(utterance);
    }, 100);
  });
}; 